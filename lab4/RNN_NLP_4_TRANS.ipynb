{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Używane urządzenie: GPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForMaskedLM\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Sprawdź dostępność GPU i wybierz urządzenie\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Używane urządzenie: {'GPU' if device == 0 else 'CPU'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekst oryginalny (EN): >>pol<< Hello, world!This is a sample text to be translated.\n",
      "Tłumaczenie (PL): Cześć, świat! To jest tekst próbny, które ma być przetłumaczony.\n"
     ]
    }
   ],
   "source": [
    "# ZAD 1\n",
    "# Załaduj pipeline do tłumaczenia En -> Pl\n",
    "# Model Helsinki-NLP jest popularnym wyborem dla wielu par językowych\n",
    "translator_en_pl = pipeline(\"translation_en_to_pl\", model=\"Helsinki-NLP/opus-mt-en-mul\", device=device)\n",
    "\n",
    "# Tekst do przetłumaczenia\n",
    "text_en = \">>pol<< Hello, world!This is a sample text to be translated.\"\n",
    "\n",
    "# Wykonaj tłumaczenie                                           \n",
    "translation_result = translator_en_pl(text_en)\n",
    "\n",
    "# Wyświetl wynik\n",
    "print(f\"Tekst oryginalny (EN): {text_en}\")\n",
    "# Wynik jest listą słowników, bierzemy pierwszy element i klucz 'translation_text'\n",
    "print(f\"Tłumaczenie (PL): {translation_result[0]['translation_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wykryty język źródłowy: fr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekst oryginalny (FR): Bonjour le monde! Ceci est un exemple de texte.\n",
      "Tłumaczenie (PL): Witaj świat! To jest przykład tekstu.\n"
     ]
    }
   ],
   "source": [
    "# ZADD 2\n",
    "from langdetect import detect\n",
    "\n",
    "text_unknown_lang = \"Bonjour le monde! Ceci est un exemple de texte.\"\n",
    "\n",
    "try:\n",
    "    # Wykryj język źródłowy\n",
    "    source_language = detect(text_unknown_lang)\n",
    "    print(f\"Wykryty język źródłowy: {source_language}\")\n",
    "\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-{source_language}-pl\"\n",
    "    translator_dynamic = pipeline(\"translation\", model=model_name, device=device)\n",
    "\n",
    "    # Tłumacz\n",
    "    translation_dynamic_result = translator_dynamic(text_unknown_lang)\n",
    "\n",
    "    print(f\"Tekst oryginalny ({source_language.upper()}): {text_unknown_lang}\")\n",
    "    print(f\"Tłumaczenie (PL): {translation_dynamic_result[0]['translation_text']}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Wystąpił błąd podczas detekcji lub tłumaczenia: {e}\")\n",
    "    print(\"Upewnij się, że biblioteka langdetect jest zainstalowana i tekst nie jest zbyt krótki lub niejednoznaczny.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wykryty język źródłowy: en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Maskowanie i Uzupełnianie HERBERT (na tłumaczeniu PL) ---\n",
      "Oryginalne tłumaczenie (PL): Gilgamesz i Enkidu zabijają Niebiańskiego Byka, obrażając przy tym Isztar, po czym bogowie decydują się skazać Enkidu na śmierć, zadając mu śmiertelną chorobę.\n",
      "Zdanie z maską: Gilgamesz i Enkidu zabijają Niebiańskiego Byka , obrażając przy tym Isztar , po czym bogowie decydują się <mask>ć Enkidu na śmierć , zadając mu śmiertelną chorobę .\n",
      "\n",
      "Sugestie uzupełnienia:\n",
      "- Gilgamesz i Enkidu zabijają Niebiańskiego Byka , obrażając przy tym Isztar , po czym bogowie decydują się na ć Enkidu na śmierć , zadając mu śmiertelną chorobę . (Score: 0.3848)\n",
      "- Gilgamesz i Enkidu zabijają Niebiańskiego Byka , obrażając przy tym Isztar , po czym bogowie decydują się zabić ć Enkidu na śmierć , zadając mu śmiertelną chorobę . (Score: 0.0468)\n",
      "- Gilgamesz i Enkidu zabijają Niebiańskiego Byka , obrażając przy tym Isztar , po czym bogowie decydują się wydać ć Enkidu na śmierć , zadając mu śmiertelną chorobę . (Score: 0.0304)\n",
      "- Gilgamesz i Enkidu zabijają Niebiańskiego Byka , obrażając przy tym Isztar , po czym bogowie decydują się już ć Enkidu na śmierć , zadając mu śmiertelną chorobę . (Score: 0.0234)\n",
      "- Gilgamesz i Enkidu zabijają Niebiańskiego Byka , obrażając przy tym Isztar , po czym bogowie decydują się ostatecznie ć Enkidu na śmierć , zadając mu śmiertelną chorobę . (Score: 0.0222)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "# Tekst wejściowy\n",
    "input_text = \"Gilgamesh and Enkidu kill the Bull of Heaven, insulting Ishtar in the process, after which the gods decide to sentence Enkidu to death and kill him by giving him a fatal illness.\"\n",
    "\n",
    "# 1. Wykryj język źródłowy\n",
    "try:\n",
    "    source_lang = detect(input_text)\n",
    "    print(f\"Wykryty język źródłowy: {source_lang}\")\n",
    "except Exception as e:                          \n",
    "    print(f\"Błąd detekcji języka: {e}\")\n",
    "    source_lang = 'en'\n",
    "\n",
    "translator_google = Translator()\n",
    "target_languages = ['pl', 'de', 'fr', 'es', 'it']\n",
    "translations = {}\n",
    "\n",
    "translations['pl'] = \"Gilgamesz i Enkidu zabijają Niebiańskiego Byka, obrażając przy tym Isztar, po czym bogowie decydują się skazać Enkidu na śmierć, zadając mu śmiertelną chorobę.\"\n",
    "translations['de'] = \"Gilgamesch und Enkidu töten den Himmelsstier und beleidigen dabei Ishtar. Daraufhin beschließen die Götter, Enkidu zum Tode zu verurteilen und ihn durch eine tödliche Krankheit zu töten.\"\n",
    "translations['fr'] = \"Gilgamesh et Enkidu tuent le Taureau du Ciel, insultant Ishtar au passage, après quoi les dieux décident de condamner Enkidu à mort et de le tuer en lui infligeant une maladie mortelle.\"\n",
    "translations['es'] = \"Gilgamesh y Enkidu matan al Toro del Cielo, insultando a Ishtar en el proceso, después de lo cual los dioses deciden sentenciar a Enkidu a muerte y matarlo dándole una enfermedad fatal.\"\n",
    "translations['it'] = \"Gilgamesh ed Enkidu uccidono il Toro Celeste, insultando Ishtar; dopodiché gli dei decidono di condannare a morte Enkidu e di ucciderlo infliggendogli una malattia mortale.\"\n",
    "\n",
    "\n",
    "herbert_model_name = \"allegro/herbert-base-cased\"\n",
    "fill_mask_pipeline = pipeline('fill-mask', model=herbert_model_name, tokenizer=herbert_model_name, device=device)\n",
    "herbert_tokenizer = AutoTokenizer.from_pretrained(herbert_model_name)\n",
    "\n",
    "print(\"\\n--- Maskowanie i Uzupełnianie HERBERT (na tłumaczeniu PL) ---\")\n",
    "\n",
    "polish_translation = translations.get('pl')\n",
    "\n",
    "if polish_translation:\n",
    "\n",
    "    tokens = herbert_tokenizer.tokenize(polish_translation)\n",
    "    token_indices = list(range(len(tokens)))\n",
    "\n",
    "    # 4. Wstaw token <mask> w losowym miejscu w środkowej części\n",
    "    if len(tokens) > 3:\n",
    "        # Wybierz indeks mniej więcej w środku (np. między 25% a 75% długości)\n",
    "        min_idx = max(1, len(tokens) // 4)\n",
    "        max_idx = min(len(tokens) - 2, 3 * len(tokens) // 4)\n",
    "        if max_idx > min_idx:\n",
    "            mask_index = random.randint(min_idx, max_idx)\n",
    "\n",
    "            # Zamień token na maskę\n",
    "            masked_tokens = tokens[:mask_index] + [herbert_tokenizer.mask_token] + tokens[mask_index+1:]\n",
    "\n",
    "            # Połącz tokeny z powrotem w zdanie dla pipeline'u fill-mask\n",
    "            # Tokenizer.convert_tokens_to_string() jest bardziej poprawny niż proste join\n",
    "            masked_sentence = herbert_tokenizer.convert_tokens_to_string(masked_tokens)\n",
    "\n",
    "            print(f\"Oryginalne tłumaczenie (PL): {polish_translation}\")\n",
    "            print(f\"Zdanie z maską: {masked_sentence}\")\n",
    "\n",
    "            # 5. Uzupełnij lukę modelem HERBERT\n",
    "            try:\n",
    "                filled_results = fill_mask_pipeline(masked_sentence)\n",
    "                print(\"\\nSugestie uzupełnienia:\")\n",
    "                for result in filled_results:\n",
    "                    # Wynik zawiera całe zdanie z uzupełnioną maską\n",
    "                    print(f\"- {result['sequence']} (Score: {result['score']:.4f})\")\n",
    "            except Exception as e:\n",
    "                print(f\"Błąd podczas uzupełniania maski: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Zdanie jest zbyt krótkie, aby wstawić maskę w środkowej części.\")\n",
    "    else:\n",
    "         print(\"Zdanie jest zbyt krótkie do maskowania.\")\n",
    "else:\n",
    "    print(\"Nie udało się uzyskać polskiego tłumaczenia do dalszego przetwarzania.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wykryty język źródłowy: pl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tłumaczenie bazowe (EN): I make a two-track, the shell drops after the shots, revenge and murders, dirty hands, bloody blouse.\n",
      "\n",
      "Rozpoczynam 5 tłumaczeń wtórnych (1 cykl/e)...\n",
      "Cykl 1/1\n",
      "  Tłumaczenie: pl -> en (model: Helsinki-NLP/opus-mt-pl-en)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Wynik (en): I make a two-track, the shell drops after the shots, revenge and murders, dirty hands, bloody blouse...\n",
      "  Tłumaczenie: en -> de (model: Helsinki-NLP/opus-mt-en-de)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Wynik (de): Ich mache eine Zweispur, die Schale fällt nach den Schüssen, Rache und Morde, schmutzige Hände, blut...\n",
      "  Tłumaczenie: de -> fr (model: Helsinki-NLP/opus-mt-de-fr)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Wynik (fr): Je fais une double piste, la coupe tombe après les coups de feu, la vengeance et les meurtres, les m...\n",
      "  Tłumaczenie: fr -> es (model: Helsinki-NLP/opus-mt-fr-es)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Wynik (es): Estoy haciendo una doble pista, la copa cae después de los disparos, la venganza y los asesinatos, l...\n",
      "  Tłumaczenie: es -> pl (model: Helsinki-NLP/opus-mt-es-pl)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Wynik (pl): Robię podwójny trop, drink spada po strzelaninie, zemście i morderstwach, brudne ręce, krwawa bluzka...\n",
      "\n",
      "Tekst po 5 tłumaczeniach: Robię podwójny trop, drink spada po strzelaninie, zemście i morderstwach, brudne ręce, krwawa bluzka.\n",
      "\n",
      "Odległość Levenshteina między tekstem początkowym a końcowym: 52\n",
      "Znormalizowana odległość: 0.5149\n",
      "Wynik różni się znacząco od oryginału.\n"
     ]
    }
   ],
   "source": [
    "# ZADD 4\n",
    "import Levenshtein\n",
    "\n",
    "initial_text = \"Robię dwutakt, po strzałach spada łuska. Zemsta i zabójstwa, brudne ręce, we krwi bluzka\"\n",
    "\n",
    "# 1. Wykryj język źródłowy\n",
    "try:\n",
    "    source_lang = detect(initial_text)\n",
    "    print(f\"Wykryty język źródłowy: {source_lang}\")\n",
    "    if source_lang != 'pl':\n",
    "        print(\"Ostrzeżenie: Przykład zakłada tekst po polsku dla łatwiejszego doboru modeli. Dostosuj modele, jeśli język jest inny.\")\n",
    "except Exception as e:\n",
    "    print(f\"Błąd detekcji języka: {e}\")\n",
    "    source_lang = 'pl' # Załóżmy polski w razie błędu\n",
    "    \n",
    "    \n",
    "# 2. Przetłumacz na angielski i polski (jako baseline)\n",
    "try:\n",
    "    translator_pl_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-pl-en\", device=device)\n",
    "    base_translation_en = translator_pl_en(initial_text)[0]['translation_text']\n",
    "    print(f\"Tłumaczenie bazowe (EN): {base_translation_en}\")\n",
    "except Exception as e:\n",
    "    print(f\"Błąd tłumaczenia bazowego: {e}\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "# 3. Sekwencja tłumaczeń wtórnych\n",
    "translation_sequence = [\n",
    "    (\"Helsinki-NLP/opus-mt-pl-en\", \"en\"),\n",
    "    (\"Helsinki-NLP/opus-mt-en-de\", \"de\"),\n",
    "    (\"Helsinki-NLP/opus-mt-de-fr\", \"fr\"),\n",
    "    (\"Helsinki-NLP/opus-mt-fr-es\", \"es\"),\n",
    "    (\"Helsinki-NLP/opus-mt-es-pl\", \"pl\") \n",
    "]\n",
    "\n",
    "num_cycles = 1\n",
    "iterations = len(translation_sequence) * num_cycles\n",
    "print(f\"\\nRozpoczynam {iterations} tłumaczeń wtórnych ({num_cycles} cykl/e)...\")\n",
    "\n",
    "current_text = initial_text\n",
    "current_lang = source_lang\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    print(f\"Cykl {i+1}/{num_cycles}\")\n",
    "    for model_name, target_lang in translation_sequence:\n",
    "        print(f\"  Tłumaczenie: {current_lang} -> {target_lang} (model: {model_name})\")\n",
    "        try:\n",
    "            translator = pipeline(\"translation\", model=model_name, device=device)\n",
    "\n",
    "            translated_text = translator(current_text)[0]['translation_text']\n",
    "\n",
    "            current_text = translated_text\n",
    "            current_lang = target_lang\n",
    "            print(f\"    Wynik ({target_lang}): {current_text[:100]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"    BŁĄD podczas tłumaczenia modelem {model_name}: {e}\")\n",
    "            print(\"    Przerwanie sekwencji tłumaczeń.\")\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "final_text = current_text\n",
    "print(f\"\\nTekst po {iterations} tłumaczeniach: {final_text}\")\n",
    "\n",
    "# 4. Oblicz metrykę Levenshteina\n",
    "# Porównujemy tekst początkowy z tekstem końcowym (który powinien być w tym samym języku co początkowy)\n",
    "if current_lang == source_lang:\n",
    "    distance = Levenshtein.distance(initial_text, final_text)\n",
    "\n",
    "    max_len = max(len(initial_text), len(final_text))\n",
    "    normalized_distance = distance / max_len if max_len > 0 else 0\n",
    "\n",
    "    print(f\"\\nOdległość Levenshteina między tekstem początkowym a końcowym: {distance}\")\n",
    "    print(f\"Znormalizowana odległość: {normalized_distance:.4f}\")\n",
    "    if normalized_distance < 0.1:\n",
    "        print(\"Wynik jest bardzo zbliżony do oryginału.\")\n",
    "    elif normalized_distance < 0.3:\n",
    "        print(\"Wynik jest dość podobny do oryginału.\")\n",
    "    elif normalized_distance < 0.6:\n",
    "        print(\"Wynik różni się znacząco od oryginału.\")\n",
    "    else:\n",
    "        print(\"Wynik jest bardzo różny od oryginału.\")\n",
    "else:\n",
    "    print(f\"\\nTekst końcowy jest w języku '{current_lang}', a oczekiwano '{source_lang}'. Nie można bezpośrednio porównać metryką Levenshteina.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odczytano plik PDF: PRZYKLADOWYPDFEN.pdf (Liczba stron: 1)\n",
      "  Odczytano tekst ze strony 1...\n"
     ]
    }
   ],
   "source": [
    "## ZAD 5 \n",
    "# 1. Wczytaj tekst z pliku PDF za pomocą PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "pdf_file_path = 'PRZYKLADOWYPDFEN.pdf'\n",
    "output_txt_path = 'PRZYKLADOWYPDFEN_pypdf2.txt'\n",
    "\n",
    "extracted_text = \"\"\n",
    "try:\n",
    "    reader = PdfReader(pdf_file_path)\n",
    "    print(f\"Odczytano plik PDF: {pdf_file_path} (Liczba stron: {len(reader.pages)})\")\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            print(f\"  Odczytano tekst ze strony {i+1}...\")\n",
    "            extracted_text += text + \"\\n\" # Dodaj nową linię między stronami\n",
    "        else:\n",
    "            print(f\"  Strona {i+1} nie zawierała możliwego do wyekstrahowania tekstu (może być obrazem?).\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"BŁĄD: Plik PDF '{pdf_file_path}' nie został znaleziony.\")\n",
    "    # Zakończ, jeśli plik nie istnieje\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"BŁĄD podczas odczytu pliku PDF: {e}\")\n",
    "    # Zakończ w razie innych błędów odczytu\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rozpoczynanie tłumaczenia...\n",
      "Tłumaczenie zakończone.\n",
      "\n",
      "Przetłumaczony tekst został zapisany do pliku: PRZYKLADOWYPDFEN_pypdf2.txt\n",
      "\n",
      "--- Przetłumaczony tekst (początek) ---\n",
      "Jest to pierwsza strona przykładowego dokumentu PDF. Zawiera on jakiś tekst w języku angielskim. Rozpakujemy ten tekst za pomocą PyPDF2 i przetłumaczymy go. Dodajmy kolejne zdanie za dobrą miarę. Naturalne przetwarzanie języka jest fascynujące....\n",
      "--- Koniec fragmentu ---\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel\n",
    "source_lang = \"eng\"\n",
    "target_lang = \"pol\"\n",
    "\n",
    "model_name = f\"Allegro/BiDi-{source_lang}-{target_lang}\"\n",
    "\n",
    "translated_text = \"\"\n",
    "if extracted_text:\n",
    "    print(\"\\nRozpoczynanie tłumaczenia...\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "        text = f\">>{target_lang}<<\" + \" \" + extracted_text\n",
    "\n",
    "        batch_to_translate = [text]\n",
    "        translations = model.generate(**tokenizer.batch_encode_plus(batch_to_translate, return_tensors=\"pt\"))\n",
    "        translated_text = tokenizer.batch_decode(translations, skip_special_tokens=True, clean_up_tokenization_spaces=True)[0]\n",
    "\n",
    "        print(\"Tłumaczenie zakończone.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"BŁĄD podczas tłumaczenia: {e}\")\n",
    "\n",
    "# 3. Zapisz wynik do pliku tekstowego\n",
    "if translated_text:\n",
    "    try:\n",
    "        with open(output_txt_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(translated_text)\n",
    "        print(f\"\\nPrzetłumaczony tekst został zapisany do pliku: {output_txt_path}\")\n",
    "        print(\"\\n--- Przetłumaczony tekst (początek) ---\")\n",
    "        print(translated_text[:500] + \"...\")\n",
    "        print(\"--- Koniec fragmentu ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"BŁĄD podczas zapisu do pliku '{output_txt_path}': {e}\")\n",
    "elif not extracted_text:\n",
    "     print(\"\\nNie zapisano wyniku, ponieważ nie udało się wyekstrahować tekstu z PDF.\")\n",
    "else:\n",
    "     print(\"\\nNie zapisano wyniku, ponieważ wystąpił błąd podczas tłumaczenia.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
